{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ceedf981",
   "metadata": {},
   "source": [
    "# 멋진 작사가 만들기\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f29da359",
   "metadata": {},
   "source": [
    "## 1. 첫시도\n",
    "\n",
    "- BATCH_SIZE = 256 -> 128 로 적용\n",
    "- 모델의 Embedding Size : 256 -> 512 로 변경, Hidden Size : 1024(변경없음) 적용"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37603ca",
   "metadata": {},
   "source": [
    "## 라이브러리 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e821d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4899ec88",
   "metadata": {},
   "source": [
    "## 데이터 읽어오기\n",
    "___\n",
    "\n",
    "- **`glob` 모듈을 사용하여 파일을 읽어오기**\n",
    "- **모든 `txt` 파일을 읽어온 후, `raw_corpus` 리스트에 문장 단위로 저장!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "894597ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\", 'It goes like this', 'The fourth, the fifth']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담는다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35a69626",
   "metadata": {},
   "source": [
    "## 데이터 정제\n",
    "___\n",
    "\n",
    "- **`preprocess_sentence()` 함수를 사용하여 데이터 정제.**\n",
    "- **지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc4bee1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "# 입력된 문장을\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백을 지움\n",
    "#     2. 특수문자 양쪽에 공백 삽입\n",
    "#     3. 여러개의 공백은 하나의 공백으로 바꿈\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿈\n",
    "#     5. 다시 양쪽 공백을 지움\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보자.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bfa4b4",
   "metadata": {},
   "source": [
    "- **공백인 문장은 길이를 검사하여 길이가 0이라면 제외**\n",
    "- **토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94662bf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> now i ve heard there was a secret chord <end>',\n",
       " '<start> that david played , and it pleased the lord <end>',\n",
       " '<start> but you don t really care for music , do you ? <end>',\n",
       " '<start> it goes like this <end>',\n",
       " '<start> the fourth , the fifth <end>',\n",
       " '<start> the minor fall , the major lift <end>',\n",
       " '<start> the baffled king composing hallelujah hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah your faith was strong but you needed proof <end>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 정제된 문장을 모음\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    # 원하지 않는 문장은 건너뜀\n",
    "    if len(sentence) == 0: continue\n",
    "    \n",
    "    # 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    # split()메소드로 단어 15개 이상 건너뜀\n",
    "    if len(preprocessed_sentence.split()) > 15: continue\n",
    "        \n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과 10개 확인\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a408462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    4 ...    0    0    0]\n",
      " [   2   15 2971 ...    0    0    0]\n",
      " [   2   33    7 ...   46    3    0]\n",
      " ...\n",
      " [   2    4  117 ...    0    0    0]\n",
      " [   2  258  195 ...   12    3    0]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f0fb5f5dd30>\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 할 때 텐서플로우의 Tokenizer, pad_sequences 사용\n",
    "\n",
    "def tokenize(corpus):\n",
    "    # 12000단어를 기억할 수 있는 tokenizer를 만듦\n",
    "    # 이미 문장을 정제했으니 filters가 필요없음\n",
    "    # 12000단어에 포함되지 못한 단어는 '<unk>'로 바꿈\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장 완성\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춤\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춤\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8322e26",
   "metadata": {},
   "source": [
    "- **생성된 텐서 데이터를 65번째부터 10행까지만 출력해 확인해 본다.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8583b574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2  175  317  175  317   15    6 1566   26 7678    3    0    0    0\n",
      "     0]\n",
      " [   2  175  317   15    6 2425 1710    3    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2  175   37   41  494  337    3    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2   23  223  632  107  223  536   32  731    3    0    0    0    0\n",
      "     0]\n",
      " [   2  175  431   10  223 1336    3    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2  175  607    9  900   20 6829    3    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2    8    9  168 5381 1165    3    0    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2  175  317  175  317   15    7   36   12   52    3    0    0    0\n",
      "     0]\n",
      " [   2  175  317   15    7  164   48    3    0    0    0    0    0    0\n",
      "     0]\n",
      " [   2  175  317   15    7   95  105 3173    3    0    0    0    0    0\n",
      "     0]]\n"
     ]
    }
   ],
   "source": [
    "print(tensor[64:74, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "749fe489",
   "metadata": {},
   "source": [
    "- **단어 사전이 어떻게 구축되었는지 아래와 같이 확인**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "31f1aa39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : <unk>\n",
      "2 : <start>\n",
      "3 : <end>\n",
      "4 : i\n",
      "5 : ,\n",
      "6 : the\n",
      "7 : you\n",
      "8 : and\n",
      "9 : a\n",
      "10 : to\n"
     ]
    }
   ],
   "source": [
    "for idx in tokenizer.index_word:\n",
    "    print(idx, \":\", tokenizer.index_word[idx])\n",
    "\n",
    "    if idx >= 10: break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17abc0c",
   "metadata": {},
   "source": [
    "## 평가 데이터셋 분리\n",
    "___\n",
    "\n",
    "### ***훈련 데이터와 평가 데이터를 분리!***\n",
    "\n",
    "- `tokenize()` 함수로 데이터를 Tensor로 변환한 후, \n",
    "- `sklearn` 모듈의 `train_test_split()` 함수를 사용해 훈련 데이터와 평가 데이터를 분리.\n",
    "- **단어장의 크기는 12,000**!\n",
    "- **총 데이터의 20%** 를 평가 데이터셋으로 사용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd2062e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   50    4   95  303   62   53    9  946 6269    3    0    0    0]\n",
      "[  50    4   95  303   62   53    9  946 6269    3    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성\n",
    "src_input = tensor[:, :-1]  \n",
    "\n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8b890633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (124981, 14)\n",
      "Target Train: (124981, 14)\n",
      "Source Val: (31246, 14)\n",
      "Target Val: (31246, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size = 0.2, random_state = 15) \n",
    "\n",
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)\n",
    "print(\"Source Val:\", enc_val.shape)\n",
    "print(\"Target Val:\", dec_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e18100d1",
   "metadata": {},
   "source": [
    "- **model.summary() 확인용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88d14f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((128, 14), (128, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(enc_train) #텐서의 1차원, 전체 문장의 개수\n",
    "BATCH_SIZE = 128        #문장의 개수\n",
    "steps_per_epoch = BUFFER_SIZE // BATCH_SIZE\n",
    "\n",
    "# tokenizer가 구축한 단어사전 내 12000개 + 0:<pad>를 포함\n",
    "VOCAB_SIZE = tokenizer.num_words + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((enc_val_train, dec_val_train))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c4fbc9c",
   "metadata": {},
   "source": [
    "## 인공지능 만들기\n",
    "___\n",
    "\n",
    "- **모델의 Embedding Size = 512로 조절하여 10 Epoch 안에 `val_loss` 값을 2.2 아하로 모델 설계!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "071b8c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 512  #단어 하나의 특징 수\n",
    "hidden_size = 1024    #퍼셉트론의 개수\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cc6a757",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(128, 14, 12001), dtype=float32, numpy=\n",
       "array([[[ 2.2828850e-05,  5.1902159e-04,  2.9014645e-04, ...,\n",
       "         -3.1061580e-05,  1.2831355e-04, -1.6740520e-04],\n",
       "        [ 6.2272785e-04,  6.1133143e-04,  6.1405235e-04, ...,\n",
       "          1.1995664e-04,  3.9273695e-04, -1.6417052e-04],\n",
       "        [ 1.2268894e-03,  4.8101216e-04,  7.9033722e-04, ...,\n",
       "          2.7912183e-04,  5.9017254e-04, -2.8152767e-04],\n",
       "        ...,\n",
       "        [ 1.6767555e-03,  2.1154208e-04,  7.7606608e-05, ...,\n",
       "          1.2235155e-03,  9.0915768e-04, -3.7487381e-04],\n",
       "        [ 1.4596393e-03,  2.8394168e-04,  3.5734585e-04, ...,\n",
       "          8.2349981e-04,  6.2528660e-04, -6.4893637e-04],\n",
       "        [ 1.0099153e-03,  4.0639611e-04,  8.3577196e-04, ...,\n",
       "          4.4392890e-04,  1.6132230e-04, -9.7023067e-04]],\n",
       "\n",
       "       [[ 2.2828850e-05,  5.1902159e-04,  2.9014645e-04, ...,\n",
       "         -3.1061580e-05,  1.2831355e-04, -1.6740520e-04],\n",
       "        [ 2.1478291e-04,  1.1100408e-03,  2.8053846e-04, ...,\n",
       "         -2.4341368e-04,  2.9978700e-04, -2.4060051e-04],\n",
       "        [ 3.5176647e-04,  1.2377115e-03,  2.5408593e-04, ...,\n",
       "         -6.1759941e-04,  2.2777016e-04,  9.6919621e-06],\n",
       "        ...,\n",
       "        [ 9.7028317e-04, -3.3522572e-04,  9.0603746e-04, ...,\n",
       "         -2.0057629e-03, -1.3119855e-03,  4.2670555e-04],\n",
       "        [ 4.3614855e-04, -2.9167670e-04,  1.3447820e-03, ...,\n",
       "         -1.9556903e-03, -1.6904558e-03,  7.5705495e-05],\n",
       "        [-1.2821300e-04, -2.7120498e-04,  1.8109746e-03, ...,\n",
       "         -1.9069229e-03, -1.9954604e-03, -3.0311238e-04]],\n",
       "\n",
       "       [[ 2.2828850e-05,  5.1902159e-04,  2.9014645e-04, ...,\n",
       "         -3.1061580e-05,  1.2831355e-04, -1.6740520e-04],\n",
       "        [ 2.8269552e-04,  1.0326225e-03,  2.9198392e-04, ...,\n",
       "         -3.3871067e-04,  3.7592629e-04,  2.6739654e-04],\n",
       "        [ 3.1971410e-04,  1.2399539e-03,  1.4794113e-04, ...,\n",
       "         -1.8873035e-04,  5.3594558e-04,  6.8303628e-04],\n",
       "        ...,\n",
       "        [-3.6714051e-04,  1.1123151e-03,  2.5376892e-03, ...,\n",
       "         -1.0670139e-03, -2.6868631e-03, -1.2993782e-03],\n",
       "        [-9.3498465e-04,  9.9475076e-04,  2.9843803e-03, ...,\n",
       "         -1.1756655e-03, -2.8421700e-03, -1.6594683e-03],\n",
       "        [-1.4582401e-03,  8.3651155e-04,  3.3932549e-03, ...,\n",
       "         -1.2607994e-03, -2.8924248e-03, -1.9430727e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 2.2828850e-05,  5.1902159e-04,  2.9014645e-04, ...,\n",
       "         -3.1061580e-05,  1.2831355e-04, -1.6740520e-04],\n",
       "        [ 3.0126987e-04,  5.1118206e-04,  2.5191435e-04, ...,\n",
       "          2.5255093e-04,  4.4453747e-04, -2.9783972e-04],\n",
       "        [ 6.8577629e-04,  1.6127503e-04,  1.9849076e-05, ...,\n",
       "          4.9637991e-04,  8.1791339e-04, -1.6082491e-04],\n",
       "        ...,\n",
       "        [-1.2518723e-03,  8.7675400e-04,  2.7044944e-03, ...,\n",
       "         -8.2731090e-04, -1.3822494e-03, -1.3886318e-03],\n",
       "        [-1.6894385e-03,  7.1070722e-04,  3.1681592e-03, ...,\n",
       "         -9.7028352e-04, -1.6200645e-03, -1.6526124e-03],\n",
       "        [-2.0863446e-03,  5.3236954e-04,  3.5833302e-03, ...,\n",
       "         -1.0804429e-03, -1.7701661e-03, -1.8692916e-03]],\n",
       "\n",
       "       [[ 2.2828850e-05,  5.1902159e-04,  2.9014645e-04, ...,\n",
       "         -3.1061580e-05,  1.2831355e-04, -1.6740520e-04],\n",
       "        [ 1.6954620e-04,  5.3940137e-04,  6.4411730e-04, ...,\n",
       "         -4.7307013e-04,  2.2258579e-04, -2.3618263e-04],\n",
       "        [ 3.7654373e-04,  7.8286591e-04,  9.9008495e-04, ...,\n",
       "         -5.5028265e-04,  2.3414065e-04, -6.0639298e-04],\n",
       "        ...,\n",
       "        [-1.8332244e-03,  6.4320001e-04,  3.4498544e-03, ...,\n",
       "         -1.6352156e-03, -1.6525635e-03, -2.5127465e-03],\n",
       "        [-2.2234537e-03,  4.7714802e-04,  3.7627697e-03, ...,\n",
       "         -1.6396017e-03, -1.8110266e-03, -2.6200800e-03],\n",
       "        [-2.5726701e-03,  3.0861163e-04,  4.0519172e-03, ...,\n",
       "         -1.6291015e-03, -1.9024269e-03, -2.6973877e-03]],\n",
       "\n",
       "       [[ 2.2828850e-05,  5.1902159e-04,  2.9014645e-04, ...,\n",
       "         -3.1061580e-05,  1.2831355e-04, -1.6740520e-04],\n",
       "        [ 2.4703550e-04,  9.3098416e-04,  6.5781578e-04, ...,\n",
       "         -2.1833141e-04,  2.3886302e-04,  2.2349413e-04],\n",
       "        [ 4.2533356e-04,  8.1512361e-04,  5.1806739e-04, ...,\n",
       "         -3.9882652e-04,  2.5929275e-04,  2.1702886e-04],\n",
       "        ...,\n",
       "        [-2.0468195e-03, -1.1144127e-04,  2.5906106e-03, ...,\n",
       "         -1.0671488e-03, -1.5536844e-03, -2.1065944e-03],\n",
       "        [-2.4665939e-03, -1.7604370e-04,  3.0409542e-03, ...,\n",
       "         -1.1162967e-03, -1.6679430e-03, -2.2466448e-03],\n",
       "        [-2.8279487e-03, -2.4196747e-04,  3.4566370e-03, ...,\n",
       "         -1.1520823e-03, -1.7257936e-03, -2.3577972e-03]]], dtype=float32)>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러와서 임시 모델 생성 및 확인\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e62529de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        multiple                  6144512   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  multiple                  6295552   \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                multiple                  8392704   \n",
      "_________________________________________________________________\n",
      "dense (Dense)                multiple                  12301025  \n",
      "=================================================================\n",
      "Total params: 33,133,793\n",
      "Trainable params: 33,133,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 생성된 모델 살펴보기\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6eaf0122",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "977/977 [==============================] - 111s 111ms/step - loss: 3.2813 - val_loss: 2.9966\n",
      "Epoch 2/10\n",
      "977/977 [==============================] - 109s 111ms/step - loss: 2.8501 - val_loss: 2.8055\n",
      "Epoch 3/10\n",
      "977/977 [==============================] - 109s 111ms/step - loss: 2.6552 - val_loss: 2.6882\n",
      "Epoch 4/10\n",
      "977/977 [==============================] - 109s 111ms/step - loss: 2.4920 - val_loss: 2.6026\n",
      "Epoch 5/10\n",
      "977/977 [==============================] - 109s 111ms/step - loss: 2.3440 - val_loss: 2.5375\n",
      "Epoch 6/10\n",
      "977/977 [==============================] - 109s 111ms/step - loss: 2.2074 - val_loss: 2.4890\n",
      "Epoch 7/10\n",
      "977/977 [==============================] - 109s 111ms/step - loss: 2.0805 - val_loss: 2.4510\n",
      "Epoch 8/10\n",
      "977/977 [==============================] - 109s 111ms/step - loss: 1.9626 - val_loss: 2.4221\n",
      "Epoch 9/10\n",
      "977/977 [==============================] - 109s 111ms/step - loss: 1.8529 - val_loss: 2.4050\n",
      "Epoch 10/10\n",
      "977/977 [==============================] - 109s 111ms/step - loss: 1.7500 - val_loss: 2.3896\n"
     ]
    }
   ],
   "source": [
    "# optimizer 와 loss function 지정\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "history = model.fit(enc_train, dec_train, epochs=10, batch_size=128, validation_data = (enc_val, dec_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc0aae2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44c31002",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> am i scary for you <end> '"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> am\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0bf1cebb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> talking bout what i m saying , <end> '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> talking\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89fb6ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> will you still love me tomorrow , can t you see ? <end> '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> will\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2bd34212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> won t you come on over <end> '"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> won t\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be2dfb67",
   "metadata": {},
   "source": [
    "## 모델이 생성한 가사를 보고 느낀 점\n",
    "\n",
    "- 첫 느낌은 \"제법 노래 가사다운 가사가 만들어진다\" 라는 생각이 들었고 임의의 첫글자를 `<start>` 가사로 랜덤하게 떠오르는 단어들로 모델에 넣어보았는데 \"잘 만들어진 가사!!?\" 이런 느낌이었다. 모델이 생성한 가사를 바탕으로 수정해서 만들어도 되겠다는 생각을 해보았다.\n",
    "- 제법 신선한 경험이었다고 생각된다. ***여러분의 모델은 어떤가요?***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d5f712d",
   "metadata": {},
   "source": [
    "## - 첫시도 회고\n",
    "\n",
    "- 최초 초기값에서 batch_size와 Embedding Size를 변경하여 작업해 보았으나 `val_loss`의 큰 변화는 없었다고 판단된다.\n",
    "- 그 원인이 무엇인지는 아직은 정확하게 파악하기 힘들다. 과적합의 문제인지 하이퍼 파라미터의 최적화 문제인지 혹은 다른 문제가 있는것은 아니지......\n",
    "- 텍스트 제너레이션 결과가 위에서 말한바와 같이 제법 그럴싸하게 생성되었다고 판단했다.\n",
    "  다만, 문장의 길이가 다소 짧은 문장 위주로 만들어져서 val_loss를 더 낮추면 좀 더 멋진 문장이 나오리라 생각된다.\n",
    "- `val_loss` 가 **2.38**로 노드에서 제시한 기준에 미치지 못했기에 두번째 시도에서 달성해 보려한다.\n",
    "___\n",
    "\n",
    "- Load한 txt 파일중에 아래와 같이 비슷한 파일명이 있어 내용을 확인해 보니 `내용이 서로 똑같은 파일과 일부만 다른 파일`과 같이 두가지 사례가 있었다. 그 파일들은 아래를 참고 바란다.\n",
    "\n",
    ">- Kanye_West.txt 와 kanye-west.txt \n",
    ">- notorious_big.txt 와 notorious-big.txt\n",
    "\n",
    "- 파일의 내용을 들여다보면 두 파일이 중복되는 부분들이 있어서 노드에서 제시한 124,960 과는 차이가 발생할 수 밖에 없는 것으로 판단했다.\n",
    "- 큰 차이는 아니라서 그대로 진행해 보았고 데이터를 정제 후에는 어떻게 달라질지는 추후에 시간적 여유를 가지고 해보려 한다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c916059",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444908d5",
   "metadata": {},
   "source": [
    "## 2. 두번째 시도\n",
    "\n",
    "### 첫시도 대비 변경사항\n",
    "\n",
    "- loss 시각화 \n",
    "- BATCH_SIZE = 128 -> 256 으로 변경\n",
    "- 모델의 Embedding Size : 512 -> 256 으로 변경, Hidden Size : 1024 -> 2048로 변경 적용\n",
    "- `train_test_split()` 함수를 사용해 분리한 훈련 데이터에서 재분리 시도"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f2956e0",
   "metadata": {},
   "source": [
    "## 데이터 읽어오기\n",
    "___\n",
    "\n",
    "- **`glob` 모듈을 사용하여 파일을 읽어오기**\n",
    "- **모든 `txt` 파일을 읽어온 후, `raw_corpus` 리스트에 문장 단위로 저장!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fed54b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\", 'It goes like this', 'The fourth, the fifth']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담습니다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0101d9f1",
   "metadata": {},
   "source": [
    "## 데이터 정제\n",
    "___\n",
    "\n",
    "- **`preprocess_sentence()` 함수를 사용하여 데이터 정제.**\n",
    "- **지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "97271393",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "# 입력된 문장을\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백을 지움\n",
    "#     2. 특수문자 양쪽에 공백 삽입\n",
    "#     3. 여러개의 공백은 하나의 공백으로 바꿈\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿈\n",
    "#     5. 다시 양쪽 공백을 지움\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보자.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample ^-^* :-:  _ %_% -  sentence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c03c612",
   "metadata": {},
   "source": [
    "- **공백인 문장은 길이를 검사하여 길이가 0이라면 제외**\n",
    "- **토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c41e2241",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> now i ve heard there was a secret chord <end>',\n",
       " '<start> that david played , and it pleased the lord <end>',\n",
       " '<start> but you don t really care for music , do you ? <end>',\n",
       " '<start> it goes like this <end>',\n",
       " '<start> the fourth , the fifth <end>',\n",
       " '<start> the minor fall , the major lift <end>',\n",
       " '<start> the baffled king composing hallelujah hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah your faith was strong but you needed proof <end>']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 정제된 문장을 모음\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    # 원하지 않는 문장은 건너뜀\n",
    "    if len(sentence) == 0: continue\n",
    "    \n",
    "    # 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    # split()메소드로 단어 15개 이상 건너뜀\n",
    "    if len(preprocessed_sentence.split()) > 15: continue  \n",
    "        \n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과 10개 확인\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85779292",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    4 ...    0    0    0]\n",
      " [   2   15 2971 ...    0    0    0]\n",
      " [   2   33    7 ...   46    3    0]\n",
      " ...\n",
      " [   2    4  117 ...    0    0    0]\n",
      " [   2  258  195 ...   12    3    0]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f0f9c0db850>\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 할 때 텐서플로우의 Tokenizer, pad_sequences 사용\n",
    "\n",
    "def tokenize(corpus):\n",
    "    # 12000단어를 기억할 수 있는 tokenizer를 만듦\n",
    "    # 이미 문장을 정제했으니 filters가 필요없음\n",
    "    # 12000단어에 포함되지 못한 단어는 '<unk>'로 바꿈\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장 완성\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춤\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춤\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71801f35",
   "metadata": {},
   "source": [
    "## 평가 데이터셋 분리\n",
    "___\n",
    "\n",
    "### ***훈련 데이터와 평가 데이터를 분리!***\n",
    "\n",
    "- `tokenize()` 함수로 데이터를 Tensor로 변환한 후, \n",
    "- `sklearn` 모듈의 `train_test_split()` 함수를 사용해 분리한 훈련 데이터를 재분리.\n",
    "- **단어장의 크기는 12,000**!\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "700b7a73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   50    4   95  303   62   53    9  946 6269    3    0    0    0]\n",
      "[  50    4   95  303   62   53    9  946 6269    3    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성\n",
    "src_input = tensor[:, :-1]  \n",
    "\n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c97b9a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (124981, 14)\n",
      "Target Train: (124981, 14)\n",
      "Source Val test: (31246, 14)\n",
      "Target Val test: (31246, 14)\n",
      "Source Val Val: (15623, 14)\n",
      "Target Val Val: (15623, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 훈련, 테스트 세트 분리\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size = 0.2, random_state = 15) \n",
    "# 훈련, 검증 세트 분리\n",
    "enc_val_train, enc_val_val, dec_val_train, dec_val_val = train_test_split(enc_train, dec_train, test_size = 0.125 ,\\\n",
    "                                                                          random_state = 15) \n",
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)\n",
    "print(\"Source Val test:\", enc_val.shape)\n",
    "print(\"Target Val test:\", dec_val.shape)\n",
    "print(\"Source Val Val:\", enc_val_val.shape)\n",
    "print(\"Target Val Val:\", dec_val_val.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b32cc8",
   "metadata": {},
   "source": [
    "- **model.summary() 확인용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "394575d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(enc_train) #텐서의 1차원, 전체 문장의 개수\n",
    "BATCH_SIZE = 256        #문장의 개수\n",
    "steps_per_epoch = BUFFER_SIZE // BATCH_SIZE\n",
    "\n",
    "# tokenizer가 구축한 단어사전 내 12000개 + 0:<pad>를 포함\n",
    "VOCAB_SIZE = tokenizer.num_words + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((enc_val_train, dec_val_train))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95399d0c",
   "metadata": {},
   "source": [
    "## 인공지능 만들기\n",
    "___\n",
    "\n",
    "- **모델의 Hidden Size = 2048로 조절하여 10 Epoch 안에 `val_loss` 값을 2.2 이하로 모델 설계!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8c774cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "#         self.drop = tf.keras.layers.Dropout(0.5)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 256  #단어 하나의 특징 수\n",
    "hidden_size = 2048    #퍼셉트론의 개수\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "83725ef0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-1.95437184e-04, -3.52773095e-05,  1.15309791e-04, ...,\n",
       "         -5.33314305e-05,  2.59980123e-04, -1.30623652e-04],\n",
       "        [-4.55428293e-04,  3.44728032e-05, -1.21135694e-04, ...,\n",
       "         -7.96695676e-05,  5.56986022e-04, -1.74602144e-04],\n",
       "        [-2.76521983e-04, -5.36673870e-05, -2.27313038e-04, ...,\n",
       "         -7.12502151e-05,  8.64925329e-04, -1.58952935e-05],\n",
       "        ...,\n",
       "        [ 1.25842989e-05, -8.07101082e-04,  1.95235002e-03, ...,\n",
       "         -1.02602493e-03,  1.19710469e-03, -3.05485330e-03],\n",
       "        [ 1.31849389e-04, -1.01104868e-03,  2.12386181e-03, ...,\n",
       "         -9.59711382e-04,  1.18882011e-03, -3.40699893e-03],\n",
       "        [ 2.58464366e-04, -1.20933005e-03,  2.25572661e-03, ...,\n",
       "         -9.09548660e-04,  1.18796888e-03, -3.70446243e-03]],\n",
       "\n",
       "       [[-1.95437184e-04, -3.52773095e-05,  1.15309791e-04, ...,\n",
       "         -5.33314305e-05,  2.59980123e-04, -1.30623652e-04],\n",
       "        [ 1.26048559e-04, -1.00197765e-04, -2.79450742e-05, ...,\n",
       "         -1.76883928e-04,  3.70762398e-04, -1.72005210e-04],\n",
       "        [ 4.63025382e-04, -1.34739792e-04,  5.00499991e-05, ...,\n",
       "          3.34501274e-05,  1.33272770e-04, -2.62299989e-04],\n",
       "        ...,\n",
       "        [-1.60686643e-04, -2.67655414e-04,  1.24726549e-03, ...,\n",
       "         -7.02325080e-04,  1.20956422e-04, -2.45281449e-03],\n",
       "        [-9.53545095e-05, -4.14529844e-04,  1.53012678e-03, ...,\n",
       "         -7.41959142e-04,  7.69553808e-05, -2.81367870e-03],\n",
       "        [-5.13170016e-06, -5.83755434e-04,  1.77216809e-03, ...,\n",
       "         -7.58047740e-04,  7.51902408e-05, -3.13890213e-03]],\n",
       "\n",
       "       [[-1.95437184e-04, -3.52773095e-05,  1.15309791e-04, ...,\n",
       "         -5.33314305e-05,  2.59980123e-04, -1.30623652e-04],\n",
       "        [-5.32611739e-04,  1.05959312e-04,  2.32236256e-04, ...,\n",
       "          1.66095837e-04,  2.32303035e-04, -2.38130495e-04],\n",
       "        [-7.41143245e-04,  1.39576965e-04,  4.34818474e-04, ...,\n",
       "          1.59425428e-04,  1.37222465e-04, -1.99326008e-04],\n",
       "        ...,\n",
       "        [-2.39052126e-04,  1.01393391e-03,  6.56764721e-04, ...,\n",
       "         -6.57739758e-04,  4.65458841e-04, -5.13419393e-04],\n",
       "        [-4.94401320e-04,  1.14415714e-03,  9.23115644e-04, ...,\n",
       "         -6.72224967e-04,  4.07178275e-04, -3.97356082e-04],\n",
       "        [-6.98780641e-04,  1.39221677e-03,  9.56663338e-04, ...,\n",
       "         -5.18806570e-04,  6.09532872e-04, -3.44295229e-04]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-1.95437184e-04, -3.52773095e-05,  1.15309791e-04, ...,\n",
       "         -5.33314305e-05,  2.59980123e-04, -1.30623652e-04],\n",
       "        [-3.30148119e-04,  4.91908540e-05,  8.00120106e-05, ...,\n",
       "          4.48309511e-05,  2.29897400e-04, -5.75524282e-05],\n",
       "        [-4.88423742e-04, -2.79916840e-05, -6.89717926e-05, ...,\n",
       "          7.56804729e-05,  7.39285406e-06, -6.78262222e-05],\n",
       "        ...,\n",
       "        [-7.98595371e-04, -2.92747689e-04,  1.99039886e-03, ...,\n",
       "         -7.32483051e-04, -1.78746996e-04, -2.48509645e-03],\n",
       "        [-6.22807129e-04, -4.33558045e-04,  2.21228204e-03, ...,\n",
       "         -6.95118972e-04, -1.16125302e-04, -2.88687414e-03],\n",
       "        [-4.32031462e-04, -5.98655490e-04,  2.38149660e-03, ...,\n",
       "         -6.64631836e-04, -2.31800022e-05, -3.24257324e-03]],\n",
       "\n",
       "       [[-1.95437184e-04, -3.52773095e-05,  1.15309791e-04, ...,\n",
       "         -5.33314305e-05,  2.59980123e-04, -1.30623652e-04],\n",
       "        [-9.13432596e-05, -5.83859073e-05,  1.78700386e-04, ...,\n",
       "         -6.92939211e-05,  3.22097680e-04, -1.13840564e-04],\n",
       "        [ 2.20601956e-04, -1.57566697e-04,  8.37162297e-05, ...,\n",
       "          3.57992540e-04,  5.35090745e-04, -3.87221189e-05],\n",
       "        ...,\n",
       "        [ 2.14797197e-04,  1.44123784e-04, -1.89927712e-04, ...,\n",
       "          6.11008494e-04,  1.19271234e-03, -9.22359250e-05],\n",
       "        [ 6.40308790e-05, -5.63379617e-05, -5.79211046e-04, ...,\n",
       "          7.87989935e-04,  1.49246759e-03,  9.61049082e-05],\n",
       "        [ 9.14932898e-05, -2.33420418e-04, -4.69329621e-04, ...,\n",
       "          7.60568015e-04,  1.68201642e-03, -6.76765485e-05]],\n",
       "\n",
       "       [[-1.95437184e-04, -3.52773095e-05,  1.15309791e-04, ...,\n",
       "         -5.33314305e-05,  2.59980123e-04, -1.30623652e-04],\n",
       "        [-3.04757064e-04, -4.63704746e-05,  2.08010795e-04, ...,\n",
       "         -3.67816712e-04,  3.26767447e-04,  1.03232393e-04],\n",
       "        [ 1.10076158e-04, -1.26114770e-04,  4.60380761e-05, ...,\n",
       "         -6.51317532e-04,  3.13280732e-04,  2.42358932e-04],\n",
       "        ...,\n",
       "        [ 4.18952608e-04, -1.04616187e-03,  1.37472444e-03, ...,\n",
       "         -6.38189609e-04,  4.23242047e-04, -1.99528760e-03],\n",
       "        [ 4.17395466e-04, -1.20911491e-03,  1.66996801e-03, ...,\n",
       "         -5.92952652e-04,  4.91380575e-04, -2.41741538e-03],\n",
       "        [ 4.48775419e-04, -1.37177214e-03,  1.90807146e-03, ...,\n",
       "         -5.65879047e-04,  5.67970390e-04, -2.79967533e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러와서 임시 모델 생성 및 확인\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "15037019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                multiple                  18882560  \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              multiple                  24590049  \n",
      "=================================================================\n",
      "Total params: 80,107,489\n",
      "Trainable params: 80,107,489\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 생성된 모델 살펴보기\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a4cd2a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "489/489 [==============================] - 240s 487ms/step - loss: 3.3447 - val_loss: 2.9494\n",
      "Epoch 2/10\n",
      "489/489 [==============================] - 243s 496ms/step - loss: 2.8272 - val_loss: 2.6249\n",
      "Epoch 3/10\n",
      "489/489 [==============================] - 244s 498ms/step - loss: 2.5590 - val_loss: 2.3410\n",
      "Epoch 4/10\n",
      "489/489 [==============================] - 244s 498ms/step - loss: 2.3006 - val_loss: 2.0644\n",
      "Epoch 5/10\n",
      "489/489 [==============================] - 244s 498ms/step - loss: 2.0502 - val_loss: 1.8094\n",
      "Epoch 6/10\n",
      "489/489 [==============================] - 243s 498ms/step - loss: 1.8124 - val_loss: 1.5842\n",
      "Epoch 7/10\n",
      "489/489 [==============================] - 244s 499ms/step - loss: 1.5969 - val_loss: 1.3908\n",
      "Epoch 8/10\n",
      "489/489 [==============================] - 244s 498ms/step - loss: 1.4119 - val_loss: 1.2341\n",
      "Epoch 9/10\n",
      "489/489 [==============================] - 244s 499ms/step - loss: 1.2611 - val_loss: 1.1155\n",
      "Epoch 10/10\n",
      "489/489 [==============================] - 244s 499ms/step - loss: 1.1472 - val_loss: 1.0336\n"
     ]
    }
   ],
   "source": [
    "# optimizer 와 loss function 지정\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "history = model.fit(enc_train, dec_train, epochs=10, batch_size=256, validation_data = (enc_val_val, dec_val_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e8a7b7",
   "metadata": {},
   "source": [
    "### loss 시각화\n",
    "\n",
    "- **아래 그래프 확인하여 validation loss가 제대로 나왔는지 알아보자.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aaf7ed87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(history.history['loss'], marker='.', c='red', label='Train-set Loss')\n",
    "plt.plot(history.history['val_loss'], marker='.', c='blue', label='Validation-set Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b05c9c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "354e1b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> am i too loud for you ? <end> '"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> am\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e7695592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> talking to the moon <end> '"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> talking\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "38df6d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> will you still love me ? <end> '"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> will\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3c569c2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> won t you come see me , queen jane ? <end> '"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> won t\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b60916",
   "metadata": {},
   "source": [
    "## - 두번째 시도 회고\n",
    "\n",
    "- train_test_split() 함수를 사용해 분리한 훈련 데이터를 재분리하여 학습을 시켰더니 val_loss 가 **2.2** 이하로 떨어졌다.\n",
    "  이를 분석해 보면 한번 분리한 훈련데이터에서 검증 세트로 분리한 한것이기 때문에 이미 훈련데이터에 있는 데이터를 재분리 하였기에\n",
    "  데이터의 교집합에 생겨서 향상된 것으로 분석해 보았다. 이 방법이 정상적인 방법은 아닌것으로 판단된다.\n",
    "- 하지만 두번째 시도를 마치고 모델이 작사한 가사를 보았을 때 \"처음 드는 생각은 가사가 길어졌다!!\" 였다.\n",
    "- 첫시도 가사와 '<start>'를 동일한 단어를 입력했더니 위와 같이 나왔다.\n",
    "- 제대로 학습했다고는 할 수 없지만 정말 가사로 사용할 수 있겠다고 생각되었다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba29cae1",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "850681f1",
   "metadata": {},
   "source": [
    "## 3. 세번째 시도\n",
    "\n",
    "- BATCH_SIZE = 64, 128, 256, 512 등 다양\n",
    "- 모델의 Embedding Size : 128, 256, 512 등, Hidden Size : 256, 512, 1024, 2048 등 다양\n",
    "- dropout 적용 등 다양하게 하이파 파라미터를 조정해서 시도해 보았다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ce3d182",
   "metadata": {},
   "source": [
    "## 데이터 읽어오기\n",
    "___\n",
    "\n",
    "- **`glob` 모듈을 사용하여 파일을 읽어오기**\n",
    "- **모든 `txt` 파일을 읽어온 후, `raw_corpus` 리스트에 문장 단위로 저장!**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "104abfbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\", 'It goes like this', 'The fourth, the fifth']\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 담는다.\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:5])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36284979",
   "metadata": {},
   "source": [
    "## 데이터 정제\n",
    "___\n",
    "\n",
    "- **`preprocess_sentence()` 함수를 사용하여 데이터 정제.**\n",
    "- **지나치게 긴 문장은 다른 데이터들이 과도한 Padding을 갖게 하므로 제거.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "df0fe9bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<start> this is sample sentence . <end>\n"
     ]
    }
   ],
   "source": [
    "# 입력된 문장을\n",
    "#     1. 소문자로 바꾸고, 양쪽 공백을 지움\n",
    "#     2. 특수문자 양쪽에 공백 삽입\n",
    "#     3. 여러개의 공백은 하나의 공백으로 바꿈\n",
    "#     4. a-zA-Z?.!,¿가 아닌 모든 문자를 하나의 공백으로 바꿈\n",
    "#     5. 다시 양쪽 공백을 지움\n",
    "#     6. 문장 시작에는 <start>, 끝에는 <end>를 추가\n",
    "\n",
    "def preprocess_sentence(sentence):\n",
    "    sentence = sentence.lower().strip() # 1\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence) # 2\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence) # 3\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence) # 4\n",
    "    sentence = sentence.strip() # 5\n",
    "    sentence = '<start> ' + sentence + ' <end>' # 6\n",
    "    return sentence\n",
    "\n",
    "# 이 문장이 어떻게 필터링되는지 확인해 보\u001f.\n",
    "print(preprocess_sentence(\"This @_is ;;;sample        sentence.\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e640dc0",
   "metadata": {},
   "source": [
    "- **공백인 문장은 길이를 검사하여 길이가 0이라면 제외**\n",
    "- **토큰화 했을 때 토큰의 개수가 15개를 넘어가는 문장을 학습 데이터에서 제외**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "82274295",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<start> now i ve heard there was a secret chord <end>',\n",
       " '<start> that david played , and it pleased the lord <end>',\n",
       " '<start> but you don t really care for music , do you ? <end>',\n",
       " '<start> it goes like this <end>',\n",
       " '<start> the fourth , the fifth <end>',\n",
       " '<start> the minor fall , the major lift <end>',\n",
       " '<start> the baffled king composing hallelujah hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah <end>',\n",
       " '<start> hallelujah your faith was strong but you needed proof <end>']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 여기에 정제된 문장을 모음\n",
    "corpus = []\n",
    "\n",
    "for sentence in raw_corpus:\n",
    "    # 원하지 않는 문장은 건너뜀\n",
    "    if len(sentence) == 0: continue\n",
    "    \n",
    "    # 정제를 하고 담아주세요\n",
    "    preprocessed_sentence = preprocess_sentence(sentence)\n",
    "    \n",
    "    # split()메소드로 단어 15개 이상 건너뜀\n",
    "    if len(preprocessed_sentence.split()) > 15: continue\n",
    "        \n",
    "    corpus.append(preprocessed_sentence)\n",
    "        \n",
    "# 정제된 결과 10개 확인\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a82ddd5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2   50    4 ...    0    0    0]\n",
      " [   2   15 2971 ...    0    0    0]\n",
      " [   2   33    7 ...   46    3    0]\n",
      " ...\n",
      " [   2    4  117 ...    0    0    0]\n",
      " [   2  258  195 ...   12    3    0]\n",
      " [   2    7   34 ...    0    0    0]] <keras_preprocessing.text.Tokenizer object at 0x7f0f0d4b5340>\n"
     ]
    }
   ],
   "source": [
    "# 토큰화 할 때 텐서플로우의 Tokenizer, pad_sequences 사용\n",
    "\n",
    "def tokenize(corpus):\n",
    "    # 12000단어를 기억할 수 있는 tokenizer를 만듦\n",
    "    # 이미 문장을 정제했으니 filters가 필요없음\n",
    "    # 12000단어에 포함되지 못한 단어는 '<unk>'로 바꿈\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000, \n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    # corpus를 이용해 tokenizer 내부의 단어장 완성\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    # 준비한 tokenizer를 이용해 corpus를 Tensor로 변환\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)   \n",
    "    # 입력 데이터의 시퀀스 길이를 일정하게 맞춤\n",
    "    # 만약 시퀀스가 짧다면 문장 뒤에 패딩을 붙여 길이를 맞춤\n",
    "    # 문장 앞에 패딩을 붙여 길이를 맞추고 싶다면 padding='pre'를 사용\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "    \n",
    "    print(tensor,tokenizer)\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3601a4a6",
   "metadata": {},
   "source": [
    "## 평가 데이터셋 분리\n",
    "___\n",
    "\n",
    "### ***훈련 데이터와 평가 데이터를 분리!***\n",
    "\n",
    "- `tokenize()` 함수로 데이터를 Tensor로 변환한 후, \n",
    "- `sklearn` 모듈의 `train_test_split()` 함수를 사용해 훈련 데이터와 평가 데이터를 분리.\n",
    "- **단어장의 크기는 12,000**!\n",
    "- **총 데이터의 20%** 를 평가 데이터셋으로 사용!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0c1d143e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   2   50    4   95  303   62   53    9  946 6269    3    0    0    0]\n",
      "[  50    4   95  303   62   53    9  946 6269    3    0    0    0    0]\n"
     ]
    }
   ],
   "source": [
    "# tensor에서 마지막 토큰을 잘라내서 소스 문장을 생성\n",
    "src_input = tensor[:, :-1]  \n",
    "\n",
    "# tensor에서 <start>를 잘라내서 타겟 문장을 생성\n",
    "tgt_input = tensor[:, 1:]    \n",
    "\n",
    "print(src_input[0])\n",
    "print(tgt_input[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1582ccf8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Source Train: (124981, 14)\n",
      "Target Train: (124981, 14)\n",
      "Source Val: (31246, 14)\n",
      "Target Val: (31246, 14)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input, tgt_input, test_size = 0.2, random_state = 15) \n",
    "\n",
    "print(\"Source Train:\", enc_train.shape)\n",
    "print(\"Target Train:\", dec_train.shape)\n",
    "print(\"Source Val:\", enc_val.shape)\n",
    "print(\"Target Val:\", dec_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa0e7d9",
   "metadata": {},
   "source": [
    "- **model.summary() 확인용**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "b72ac7f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((256, 14), (256, 14)), types: (tf.int32, tf.int32)>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BUFFER_SIZE = len(enc_train) #텐서의 1차원, 전체 문장의 개수\n",
    "BATCH_SIZE = 256        #문장의 개수\n",
    "steps_per_epoch = BUFFER_SIZE // BATCH_SIZE\n",
    "\n",
    "# tokenizer가 구축한 단어사전 내 12000개 + 0:<pad>를 포함\n",
    "VOCAB_SIZE = tokenizer.num_words + 1\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "# dataset = tf.data.Dataset.from_tensor_slices((enc_val_train, dec_val_train))\n",
    "dataset = dataset.shuffle(BUFFER_SIZE)\n",
    "dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03165c69",
   "metadata": {},
   "source": [
    "## 인공지능 만들기\n",
    "___\n",
    "\n",
    "- **모델의 Embedding Size = 512로 조절하여 10 Epoch 안에 `val_loss` 값을 2.2 아하로 모델 설계!**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e413bd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "#         self.drop = tf.keras.layers.Dropout(0.5)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "#         out = self.drop(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "embedding_size = 512  #단어 하나의 특징 수\n",
    "hidden_size = 2048    #퍼셉트론의 개수\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "13539fd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-2.9107230e-04,  9.0043512e-05,  2.7629829e-04, ...,\n",
       "         -2.6796985e-04,  2.4273009e-04,  2.2444859e-04],\n",
       "        [-5.9881975e-04,  7.5742049e-05,  2.6961029e-04, ...,\n",
       "         -4.0989229e-04,  4.1193576e-04,  3.3997858e-04],\n",
       "        [-4.9813226e-04,  5.2322463e-05,  4.1118514e-04, ...,\n",
       "         -6.0079288e-04,  5.6325499e-04,  5.7505560e-04],\n",
       "        ...,\n",
       "        [ 6.7963605e-03,  1.9317300e-03,  6.6033157e-04, ...,\n",
       "         -1.8690275e-03,  5.5409633e-03,  2.4488189e-03],\n",
       "        [ 7.6374817e-03,  1.9511748e-03,  7.1088149e-04, ...,\n",
       "         -1.8388734e-03,  6.0454439e-03,  2.7348408e-03],\n",
       "        [ 8.3559826e-03,  1.9269140e-03,  7.5295946e-04, ...,\n",
       "         -1.7990590e-03,  6.4530806e-03,  2.9680277e-03]],\n",
       "\n",
       "       [[-2.9107230e-04,  9.0043512e-05,  2.7629829e-04, ...,\n",
       "         -2.6796985e-04,  2.4273009e-04,  2.2444859e-04],\n",
       "        [-4.9182301e-04, -4.5349345e-05,  1.3060331e-04, ...,\n",
       "         -4.1488800e-04,  3.9563450e-04,  2.3937291e-04],\n",
       "        [-5.1020144e-04,  8.6440086e-05,  6.2363208e-05, ...,\n",
       "         -5.5586925e-04,  5.9780979e-04,  1.9351045e-04],\n",
       "        ...,\n",
       "        [ 1.1332022e-03,  1.3647365e-03, -3.3269799e-04, ...,\n",
       "          6.3010939e-06,  2.4076551e-03, -2.4567859e-04],\n",
       "        [ 6.2216184e-04,  1.6455558e-03,  1.6986298e-04, ...,\n",
       "         -2.6990287e-04,  2.1905599e-03, -2.1365912e-04],\n",
       "        [ 9.8747364e-04,  1.9043080e-03,  5.6043261e-04, ...,\n",
       "         -5.7537184e-04,  2.4109567e-03,  9.0370544e-05]],\n",
       "\n",
       "       [[-2.9107230e-04,  9.0043512e-05,  2.7629829e-04, ...,\n",
       "         -2.6796985e-04,  2.4273009e-04,  2.2444859e-04],\n",
       "        [-8.7438815e-04,  2.6648492e-04,  5.1635999e-04, ...,\n",
       "         -3.3515762e-04,  4.3426637e-04,  5.2858109e-04],\n",
       "        [-8.6448179e-04, -3.0904990e-05,  2.9668689e-04, ...,\n",
       "         -9.3084898e-05,  1.2062129e-03,  6.0803257e-04],\n",
       "        ...,\n",
       "        [ 5.9638731e-03,  1.1315099e-03,  4.9422815e-04, ...,\n",
       "         -9.4411086e-04,  6.0666916e-03,  2.2864051e-03],\n",
       "        [ 6.9326987e-03,  1.2411418e-03,  5.5911753e-04, ...,\n",
       "         -9.8021736e-04,  6.5419134e-03,  2.5519428e-03],\n",
       "        [ 7.7605406e-03,  1.3046503e-03,  6.1817607e-04, ...,\n",
       "         -1.0163314e-03,  6.9176736e-03,  2.7775434e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-2.9107230e-04,  9.0043512e-05,  2.7629829e-04, ...,\n",
       "         -2.6796985e-04,  2.4273009e-04,  2.2444859e-04],\n",
       "        [-2.2419209e-04,  3.7567303e-04,  2.5218801e-04, ...,\n",
       "         -1.8772449e-04,  3.4506273e-04,  4.4211879e-04],\n",
       "        [-2.0791721e-04,  1.2474931e-04, -1.1410976e-04, ...,\n",
       "          2.4125857e-04,  6.6569331e-04,  5.3688040e-04],\n",
       "        ...,\n",
       "        [ 5.1457025e-03,  1.4536215e-03,  7.2575221e-04, ...,\n",
       "         -5.8050366e-04,  5.0163688e-03,  1.8826738e-03],\n",
       "        [ 6.1555291e-03,  1.5729048e-03,  8.2019635e-04, ...,\n",
       "         -6.8557041e-04,  5.5783084e-03,  2.2053884e-03],\n",
       "        [ 7.0468890e-03,  1.6229382e-03,  8.8865135e-04, ...,\n",
       "         -7.8215561e-04,  6.0504638e-03,  2.4802305e-03]],\n",
       "\n",
       "       [[-2.9107230e-04,  9.0043512e-05,  2.7629829e-04, ...,\n",
       "         -2.6796985e-04,  2.4273009e-04,  2.2444859e-04],\n",
       "        [-4.5091013e-04,  2.6467544e-04, -2.2854218e-04, ...,\n",
       "         -5.2369019e-04,  3.0823529e-04,  3.7126501e-05],\n",
       "        [-3.5476999e-04,  3.7323075e-04, -4.6555779e-04, ...,\n",
       "         -7.9055649e-04,  7.0073758e-04,  2.0010426e-04],\n",
       "        ...,\n",
       "        [-6.6071027e-04,  1.0147464e-03,  1.5508874e-03, ...,\n",
       "         -7.1261020e-04,  7.7107456e-04, -1.8416627e-03],\n",
       "        [ 3.8461073e-04,  1.3495123e-03,  1.7521060e-03, ...,\n",
       "         -1.0256862e-03,  1.4375506e-03, -1.2641189e-03],\n",
       "        [ 1.6321753e-03,  1.6131750e-03,  1.8302832e-03, ...,\n",
       "         -1.2486915e-03,  2.2340761e-03, -5.8869435e-04]],\n",
       "\n",
       "       [[-2.9107230e-04,  9.0043512e-05,  2.7629829e-04, ...,\n",
       "         -2.6796985e-04,  2.4273009e-04,  2.2444859e-04],\n",
       "        [-4.9182301e-04, -4.5349345e-05,  1.3060331e-04, ...,\n",
       "         -4.1488800e-04,  3.9563450e-04,  2.3937291e-04],\n",
       "        [-5.1823811e-04, -1.9217576e-04, -1.9858399e-04, ...,\n",
       "         -7.2063389e-04,  2.2794190e-04,  1.4115624e-04],\n",
       "        ...,\n",
       "        [ 1.0327986e-03,  7.1884668e-04, -3.1343373e-04, ...,\n",
       "         -6.5617712e-04,  8.3598701e-05, -1.1565868e-03],\n",
       "        [ 1.1158817e-03,  5.9662893e-04, -2.1006190e-04, ...,\n",
       "         -4.6421395e-04,  1.5039784e-04, -1.0721659e-03],\n",
       "        [ 1.5315143e-03,  6.4705889e-04, -3.1639653e-04, ...,\n",
       "         -5.8986060e-04,  4.8048515e-04, -5.6073169e-04]]], dtype=float32)>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터셋에서 데이터 한 배치만 불러와서 임시 모델 생성 및 확인\n",
    "for src_sample, tgt_sample in dataset.take(1): break\n",
    "\n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "402e0d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      multiple                  6144512   \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                multiple                  20979712  \n",
      "_________________________________________________________________\n",
      "lstm_7 (LSTM)                multiple                  33562624  \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              multiple                  24590049  \n",
      "=================================================================\n",
      "Total params: 85,276,897\n",
      "Trainable params: 85,276,897\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 생성된 모델 살펴보기\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "262698ea",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "245/245 [==============================] - 254s 1s/step - loss: 3.5988 - val_loss: 3.1662\n",
      "Epoch 2/10\n",
      "245/245 [==============================] - 255s 1s/step - loss: 3.0055 - val_loss: 2.9346\n",
      "Epoch 3/10\n",
      "245/245 [==============================] - 255s 1s/step - loss: 2.7957 - val_loss: 2.7899\n",
      "Epoch 4/10\n",
      "245/245 [==============================] - 256s 1s/step - loss: 2.6211 - val_loss: 2.6789\n",
      "Epoch 5/10\n",
      "245/245 [==============================] - 256s 1s/step - loss: 2.4565 - val_loss: 2.5936\n",
      "Epoch 6/10\n",
      "245/245 [==============================] - 256s 1s/step - loss: 2.2981 - val_loss: 2.5094\n",
      "Epoch 7/10\n",
      "245/245 [==============================] - 256s 1s/step - loss: 2.1452 - val_loss: 2.4473\n",
      "Epoch 8/10\n",
      "245/245 [==============================] - 256s 1s/step - loss: 1.9983 - val_loss: 2.3887\n",
      "Epoch 9/10\n",
      "245/245 [==============================] - 257s 1s/step - loss: 1.8576 - val_loss: 2.3411\n",
      "Epoch 10/10\n",
      "245/245 [==============================] - 257s 1s/step - loss: 1.7218 - val_loss: 2.3041\n"
     ]
    }
   ],
   "source": [
    "# optimizer 와 loss function 지정\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "history = model.fit(enc_train, dec_train, epochs=10, batch_size=512, validation_data = (enc_val, dec_val))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "63630805",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(8, 5))\n",
    "\n",
    "plt.plot(history.history['loss'], marker='.', c='red', label='Train-set Loss')\n",
    "plt.plot(history.history['val_loss'], marker='.', c='blue', label='Validation-set Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "42c531ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=20):\n",
    "    # 테스트를 위해서 입력받은 init_sentence도 텐서로 변환\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    while True:\n",
    "        # 1\n",
    "        predict = model(test_tensor) \n",
    "        # 2\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        # 3 \n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        # 4\n",
    "        if predict_word.numpy()[0] == end_token: break\n",
    "        if test_tensor.shape[1] >= max_len: break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 이용해 word index를 단어로 하나씩 변환 \n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "        \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "aea07136",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> am i scary for you baby <end> '"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> am\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "31e79ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> talking to the moon <end> '"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> talking\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "596b1fdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> will you still love me tomorrow <end> '"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> will\", max_len=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "670c3e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> won t you give me a sign <end> '"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, init_sentence=\"<start> won t\", max_len=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35906aa6",
   "metadata": {},
   "source": [
    "## 최종 회고\n",
    "\n",
    "- 첫번째, 두번째 시도외에도 여러가지 하이퍼 파라미터들을 조정하고, dropout 적용, learning_rate 변경 등 여러 수십가지 다양한 방법을 동원해서 `val_loss`를 **2.2**이하로 떨어뜨리기 위해 시도해 보았지만 실제 `val_loss` 값은 아래와 같은 범위에서 변동될 뿐이었다.  \n",
    ">\n",
    ">- `val_loss` 값 범위 : 약 **2.30 ~ 3.5** 사이였다.\n",
    ">\n",
    "\n",
    "- `val_loss` 향상이 되지 않아서 검색한 아래 사이트도 참고하여 변경/적용해 보았으나 결과는 위와 크게 달라지지 않았다.\n",
    "    - ['val_loss' 향상 이휴 및 정확도 문제](https://lsjsj92.tistory.com/353) \n",
    "\n",
    "- padding 과 관련하여 검색하다가 아래 링크를 참조하여 padding 도 조정해 보았지만 생각처럼 되진 않았다.\n",
    "    - [padding 관련 참고](https://blog.naver.com/qbxlvnf11/221945962124)\n",
    "    \n",
    "    \n",
    "- 루브릭 기준에 **10** epochs 에 `val_loss` **2.2** 가 기준이어서 10 epochs 이상 시도해 보지 않았지만 프로젝트 제출후에 시도해 보려한다.\n",
    "- 정확하게 무엇이 부족하거나 잘못되었기에 이렇게 밖에 안되는지 알 수가 없어서 답답하고 의기소침하게 되는 것 같다.\n",
    "- 이 노드를 진행하면서 명확하게 분석해서 아는 분이 계시다면 자료 공유 및 어드바이스 부탁드리고 싶다.\n",
    "- 앞으로 가야할 길이 멀었지만 더욱 멀게만 느껴지는 한 주를 보낸 것 같다.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
